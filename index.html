from flask import Flask, request, jsonify
from flask_cors import CORS
from sentence_transformers import SentenceTransformer
import numpy as np

app = Flask(__name__)
CORS(app)  # Allow browser to access localhost

# Load the model once at startup (768-dimensional embeddings)
print("Loading Sentence-BERT model (all-mpnet-base-v2)...")
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
print("Model loaded successfully! 768-dimensional embeddings ready.")

@app.route('/calculate_ssi', methods=['POST'])
def calculate_ssi():
    try:
        data = request.json
        
        if not data or 'texts' not in data:
            return jsonify({'error': 'No texts provided'}), 400
            
        texts = data['texts']
        
        if len(texts) < 2:
            return jsonify({'error': 'At least 2 texts required'}), 400
        
        print(f"\nProcessing {len(texts)} texts...")
        
        # Generate embeddings for all texts
        embeddings = model.encode(texts, convert_to_numpy=True)
        print(f"Generated embeddings: {embeddings.shape}")
        
        # Calculate pairwise cosine similarities
        n = len(embeddings)
        sum_similarities = 0
        pair_count = 0
        pairwise_similarities = []
        all_similarities = []
        
        for i in range(n):
            for j in range(i + 1, n):
                # Cosine similarity
                similarity = np.dot(embeddings[i], embeddings[j]) / (
                    np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])
                )
                sum_similarities += similarity
                pair_count += 1
                all_similarities.append(similarity)
                
                pairwise_similarities.append({
                    'i': i,
                    'j': j,
                    'similarity': float(similarity)
                })
                
                print(f"  Text {i+1} â†” Text {j+1}: {similarity:.6f}")
        
        # Calculate SSI using formula: 2/(n(n-1)) * sum of pairwise similarities
        ssi = (2 / (n * (n - 1))) * sum_similarities
        
        # Calculate statistics
        all_similarities = np.array(all_similarities)
        avg_similarity = np.mean(all_similarities)
        min_similarity = np.min(all_similarities)
        max_similarity = np.max(all_similarities)
        std_deviation = np.std(all_similarities)
        
        print(f"\nResults:")
        print(f"  SSI Score: {ssi:.6f}")
        print(f"  Average Similarity: {avg_similarity:.6f}")
        print(f"  Min/Max: {min_similarity:.6f} / {max_similarity:.6f}")
        print(f"  Std Deviation: {std_deviation:.6f}")
        
        return jsonify({
            'ssi': float(ssi),
            'n_texts': n,
            'n_pairs': pair_count,
            'sum_similarities': float(sum_similarities),
            'pairwise_similarities': pairwise_similarities,
            'average_similarity': float(avg_similarity),
            'min_similarity': float(min_similarity),
            'max_similarity': float(max_similarity),
            'std_deviation': float(std_deviation),
            'embedding_dimension': embeddings.shape[1]
        })
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'running',
        'model': 'sentence-transformers/all-mpnet-base-v2',
        'embedding_dimension': 768
    })

if __name__ == '__main__':
    print("\n" + "="*60)
    print("SSI Calculator Backend Server")
    print("="*60)
    print("Server running on: http://localhost:5000")
    print("Model: sentence-transformers/all-mpnet-base-v2")
    print("Embedding Dimension: 768")
    print("\nPress CTRL+C to stop the server")
    print("="*60 + "\n")
    app.run(host='localhost', port=5000, debug=True)
